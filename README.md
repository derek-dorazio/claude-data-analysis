# Data Analysis Workflow

A Claude Code agentic project for loading, joining, and analyzing local data files. Drop CSV, Excel, or JSON files into the `input/` folder and use slash commands to plan and execute analysis.

## Getting Started

### Prerequisites

- [Claude Code CLI](https://docs.anthropic.com/en/docs/claude-code)
- Python 3.8+ with pandas (`pip3 install pandas openpyxl xlrd`)
- [uv](https://docs.astral.sh/uv/) for MCP servers (`brew install uv`)
- Node.js/npm (for filesystem MCP server)

### Quick Start

```bash
# 1. Place your data files in input/
cp sales.csv customers.xlsx input/

# 2. Open Claude Code in this directory
claude

# 3. Profile your data
/explore

# 4. Plan an analysis
/plan analyze sales by customer segment

# 5. Execute the plan
/implement
```

## Commands

| Command | Purpose | Output |
|---------|---------|--------|
| `/plan <description>` | Profile input data and create a structured analysis plan | `output/plan/` |
| `/implement [plan-file]` | Execute an analysis plan — load, clean, join, analyze | `output/analysis/` |
| `/explore [file]` | Quick data profiling — schema, stats, quality flags | `output/explore/` |
| `/query <question>` | Ask a natural-language question about your data | inline + `output/reports/` |
| `/export [file] <format>` | Export results to Excel, CSV, or markdown | `output/data/` |

### Workflow

The typical workflow is **Plan → Implement**:

1. **`/plan`** reads all input files, profiles them, identifies join keys, and produces a structured analysis plan with cleaning steps and objectives
2. You review and optionally edit the plan in `output/plan/`
3. **`/implement`** picks up the plan and executes it step-by-step using Python/pandas, producing a report with findings

For quick one-off questions, use **`/query`** or **`/explore`** directly.

## Input Formats

| Format | Extensions | Notes |
|--------|-----------|-------|
| CSV | `.csv` | Auto-detects delimiter (comma, tab, pipe, semicolon) |
| Excel | `.xlsx`, `.xls` | Multi-sheet workbooks supported |
| JSON | `.json` | Flat arrays or nested objects |
| JSON Lines | `.jsonl` | One JSON object per line |

### Multi-File Analysis

The workflow is designed for multi-file analysis. Place 2+ files in `input/` and the `/plan` command will:
- Profile each file independently
- Identify candidate join keys across files
- Assess cardinality and value overlap
- Propose a join strategy (type, order, pre-cleaning)

## MCP Servers

| Server | Package | Purpose |
|--------|---------|---------|
| excel | `excel-mcp-server` | Read/write Excel workbooks with formatting |
| filesystem | `@anthropic/mcp-filesystem-server` | Enhanced file operations on input/output dirs |

MCP servers start automatically when Claude Code loads this project. Requires `uv` and `npm`.

## Skills

Reusable analysis prompts in `skills/`:

| Skill | Purpose |
|-------|---------|
| `profile-data` | Column types, distributions, nulls, uniques, sample values |
| `join-strategy` | Identify join keys, relationship types, cardinality |
| `detect-anomalies` | Outliers, unexpected values, data quality issues |
| `summarize-stats` | Descriptive statistics, aggregations, group-by summaries |

## Project Structure

```
data-analysis/
├── .claude/commands/     # Slash commands
├── skills/               # Reusable analysis prompts
├── scripts/              # Helper shell scripts
├── input/                # Your data files go here
├── output/
│   ├── plan/             # Analysis plans
│   ├── analysis/         # Full analysis reports
│   ├── explore/          # Data profiles
│   ├── data/             # Generated Excel/CSV files
│   └── reports/          # Summary reports and query results
├── templates/            # Reusable output templates
├── .mcp.json             # MCP server configuration
├── CLAUDE.md             # Project config for Claude Code
└── README.md             # This file
```

## Helper Scripts

```bash
# List all output files
./scripts/list-output.sh            # all types
./scripts/list-output.sh analysis   # just analysis reports

# Clean old output (default: 30 days)
./scripts/clean-output.sh           # 30 days
./scripts/clean-output.sh 7         # 7 days
```

## Conventions

- **Output naming**: `YYYY-MM-DD-<topic-slug>.<ext>`
- **Input files**: Never modified — all output goes to `output/`
- **Python scripts**: Ephemeral (generated by Claude, run, results saved) — the reports and data files are the deliverables
- **Reports**: Markdown format with tables and structured sections
